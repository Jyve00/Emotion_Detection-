{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard Python Operations \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "# Audio Extraction and Augmentation tools\n",
    "from scipy import signal \n",
    "import librosa \n",
    "import librosa.display \n",
    "import IPython.display as ipd\n",
    "\n",
    "# Machine Learning \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Neural Networks \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.random import set_seed\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>/Users/stephen/Emotion_Detection-/data/RAVDESS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>/Users/stephen/Emotion_Detection-/data/RAVDESS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>/Users/stephen/Emotion_Detection-/data/RAVDESS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry</td>\n",
       "      <td>/Users/stephen/Emotion_Detection-/data/RAVDESS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>/Users/stephen/Emotion_Detection-/data/RAVDESS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0    angry  /Users/stephen/Emotion_Detection-/data/RAVDESS...\n",
       "1     fear  /Users/stephen/Emotion_Detection-/data/RAVDESS...\n",
       "2     fear  /Users/stephen/Emotion_Detection-/data/RAVDESS...\n",
       "3    angry  /Users/stephen/Emotion_Detection-/data/RAVDESS...\n",
       "4  disgust  /Users/stephen/Emotion_Detection-/data/RAVDESS..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting string representing path for folder containing audio files\n",
    "Ravdess = '/Users/stephen/Emotion_Detection-/data/RAVDESS/'\n",
    "\n",
    "# Turn Path string into Path Object \n",
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "ravdess_directory_list.sort\n",
    "\n",
    "# Create empty lists to store audio paths and their labels associated with each file \n",
    "file_emotion = []\n",
    "file_path = []\n",
    "# Since each actor is in there own folder we must iterate through each folder \n",
    "for dir in ravdess_directory_list:\n",
    "    # as their are 24 different actors in our previous directory we need to extract files for each actor.\n",
    "    actor = os.listdir(Ravdess + dir)\n",
    "    for file in actor:\n",
    "        # splitting up file name to decode labels \n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        # third part in each file represents the emotion associated to that file.\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(Ravdess + dir + '/' + file)\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "# changing integers to actual emotions.\n",
    "Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data, SNR=10):   \n",
    "    \"\"\"\n",
    "    Adds Additive White Gausian Noise to signal \n",
    "    https://medium.com/analytics-vidhya/adding-noise-to-audio-clips-5d8cee24ccb\n",
    "\n",
    "    the higher the SNR the lower the noise amplitude is. \n",
    "    finds RMS value of signal \n",
    "    Finds RMS value of noise \n",
    "    Uses population formula for standard deviation\n",
    "\n",
    "    Args:\n",
    "        data (np.darray): audio time series \n",
    "        SNR (int, optional): signal to noise ratio. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        (np.darray) : [Return original signal plus random noise]\n",
    "    \"\"\"\n",
    "    RMS_s = math.sqrt(np.mean(data**2))\n",
    "    RMS_n = math.sqrt(RMS_s**2/(pow(10,SNR/10)))\n",
    "    STD_n = RMS_n \n",
    "    noise = np.random.normal(0, STD_n, data.shape[0])\n",
    "    new_data = data + noise\n",
    "    return new_data\n",
    "\n",
    "# Time Strectching \n",
    "def stretch(data, rate=0.90):\n",
    "    \"\"\"\n",
    "    Stretches audio data using librosa \n",
    "    librosa documentation: https://librosa.org/doc/main/generated/librosa.effects.time_stretch.html\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): audio time series\n",
    "        rate (float, optional): Stretch factor. If rate > 1, then the signal is sped up. If rate < 1,\n",
    "                                         then the signal is slowed down.. Defaults to 0.90.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray): audio time series stretched by the specified rate\n",
    "    \"\"\"\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    \"\"\"\n",
    "    Randomly shift timing of audio data \n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): audio time series\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray): audio time series randomly shifted in time\n",
    "    \"\"\"\n",
    "    shift_range = int(np.random.uniform(low=-1, high = 1)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "# Pre Emphasis \n",
    "def pre_emphasis(data, coef=1):\n",
    "    \"\"\"\n",
    "    Adds Pre-Emphasis to audio signal \n",
    "    info on Pre-Emphasis in speech recognition https://wiki.aalto.fi/display/ITSP/Pre-emphasis\n",
    "    librosa Pre-Emphasis documentation https://librosa.org/doc/main/generated/librosa.effects.preemphasis.html\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): audio time series\n",
    "        coef (int, optional): Pre-emphasis coefficient.. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray): pre-emphasized signal\n",
    "    \"\"\"\n",
    "    return librosa.effects.preemphasis(data, coef=1)\n",
    "\n",
    "def pitch(data, sr=16000, n_steps=3):\n",
    "    \"\"\"\n",
    "    Apply a pitch shift to an audio time series.\n",
    "    Librosa pitch shift documentation http://librosa.org/doc/main/generated/librosa.effects.pitch_shift.html\n",
    "    \n",
    "    Args:\n",
    "        data (np.ndarray): audio time series\n",
    "        sr (int, optional): sample rate. Defaults to 16000.\n",
    "        n_steps (int, optional): Shift by n_steps semitones. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray): The pitch-shifted audio time-series\n",
    "    \"\"\"\n",
    "    return librosa.effects.pitch_shift(data, sr, n_steps=1, bins_per_octave=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment data \n",
    "\n",
    "def aug_data(data, sample_rate):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features for 2D CNN\n",
    "\n",
    "def prepare_data(df, n_mfcc, noise=True, stretch=True, shift=True, pitch=True, pre_emphasis=True, mfcc):\n",
    "    X = np.empty(shape=(df.shape[0], n_mfcc, 216, 1))\n",
    "    input_length = sampling_rate * audio_duration\n",
    "\n",
    "    cnt = 0\n",
    "    for fname in tqdm(df.path):\n",
    "        file_path = fname\n",
    "        data, _ = librosa.load(file_path, sr=sampling_rate\n",
    "                               ,res_type=\"kaiser_fast\"\n",
    "                               ,duration=2.5\n",
    "                               ,offset=0.5\n",
    "                              )\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, int(input_length) - len(data) - offset), \"constant\")\n",
    "\n",
    "        # Augmentation? \n",
    "        if noise == True:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3358073929bd3d27ff594bc6528257efc4213b34ba9d7c6bd240dce3a23a83d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('torch_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
